{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d955b5f3-6b81-46ee-96d4-bbbdf5d59bd7",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Spark OCR in Healthcare\r\n",
    "\r\n",
    "Spark OCR is a commercial extension of Spark NLP for optical character recognition from images, scanned PDF documents, Microsoft DOCX and DICOM files. \r\n",
    "\r\n",
    "In this notebook we will:\r\n",
    "  - Import clinical notes in pdf format and store in delta\r\n",
    "  - Convert pdfs to image and improve image quality\r\n",
    "  - Extract text from pdfs and store resulting text data in delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28acc1ba-8bf2-4ff1-a173-8ced13ec66c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers==4.22.1 johnsnowlabs spark-nlp spark-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21135a25-7f30-4c4f-945e-f5e262aecea4",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# To prevent undesired infor from the outputs\n",
    "import logging\n",
    "logger = spark._jvm.org.apache.log4j\n",
    "logging.getLogger(\"py4j.java_gateway\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67e2049-f9eb-4100-88b6-1cd6a7e659b1",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "#import sys\n",
    "#import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "import sparknlp\n",
    "# import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.util import *\n",
    "from sparknlp.annotator import *\n",
    "# from sparknlp_jsl.base import *\n",
    "# from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    " \n",
    "# import sparkocr\n",
    "# from sparkocr.transformers import *\n",
    "# from sparkocr.utils import *\n",
    "# from sparkocr.enums import *\n",
    " \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sparknlp.training import CoNLL\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 100)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    " \n",
    "spark.sql(\"set spark.sql.legacy.allowUntypedScalaUDF=true\")\n",
    " \n",
    "print('sparknlp.version : ',sparknlp.version())\n",
    "# print('sparknlp_jsl.version : ',sparknlp_jsl.version())\n",
    "# print('sparkocr : ',sparkocr.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d74e86a-761b-4a97-9d99-a058d87a1bfc",
     "showTitle": true,
     "title": "Initial Configuration"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f77ce2-9811-44ce-807b-ac6ccca5e7ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "solacc_settings=SolAccUtil('phi_ocr')\n",
    "solacc_settings.print_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5867e198-0797-4fd2-9dc9-b7f9eb441a0a",
     "showTitle": true,
     "title": "download pdf files"
    }
   },
   "outputs": [],
   "source": [
    "remote_url='https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/data/ocr'\n",
    "for i in range(0,3):\n",
    "  solacc_settings.load_remote_data(f'{remote_url}/MT_OCR_0{i}.pdf')\n",
    "dbutils.fs.ls(solacc_settings.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401ef928-8ec0-4ec7-8067-616a25e852ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdfs_df = spark.read.format('binaryFile').load(f'{solacc_settings.data_path}/*.pdf').sort('path')\n",
    "print(\"Number of files in the folder: \", pdfs_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ab1cb5e-96ab-4bf3-9ae4-773c57b3a067",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Write pdf files to delta bronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3bed06d-3675-47c5-81e2-c5acb03f6f72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdfs_bronze_df = pdfs_df.selectExpr('sha1(path) as id','*')\n",
    "display(pdfs_bronze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d66700-a7e6-4b90-a94a-402df779ae07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdfs_bronze_df.write.mode('overwrite').save(f'{solacc_settings.delta_path}/bronze/notes_pdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e9f60a1-f00d-48e3-a7c6-68dd1b1ceb03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Parsing the Files through OCR (create bronze layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec93ee01-1a0b-4a26-99fb-4f7afae19c37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "* The pdf files can have more than one page. We will transform the document in to images per page. Than we can run OCR to get text.\n",
    "* We are using PdfToImage() to render PDF to images and ImageToText() to runs OCR for each images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "127c4975-de72-4b4d-8c48-a1024baf15b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_df = spark.read.load(f'{solacc_settings.delta_path}/bronze/notes_pdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1d48a5-7a32-488b-9901-815046eff73e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transofrm PDF document to images per page\n",
    "pdf_to_image = PdfToImage()\\\n",
    "      .setInputCol(\"content\")\\\n",
    "      .setOutputCol(\"image\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01-pdf-ocr",
   "widgets": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "notebook_environment": {},
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "trident": {
   "lakehouse": {
    "default_lakehouse": "3ca3469e-e846-4fce-b048-6a5b10a9ff57",
    "default_lakehouse_name": "sweet_house",
    "default_lakehouse_workspace_id": "f7a2eb39-d18b-4f3c-8fc3-db8793d2497e",
    "known_lakehouses": [
     {
      "id": "3ca3469e-e846-4fce-b048-6a5b10a9ff57"
     }
    ]
   }
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
